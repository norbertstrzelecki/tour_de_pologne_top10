{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tour de Pologne Top 10 finishers prediction part 1 of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next notebooks:** <br>\n",
    "[Part 2: Data stats and visuals](tdp_2_3_data_statistics_visualisation.ipynb)<br>\n",
    "[Part 3: Data  modeling](tdp_3_3_data_modeling.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for web scraping\n",
    "url_base = 'http://firstcycling.com/race.php?r=19&y='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2014, 2015, 2016, 2017, 2018]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining year range for data of interest\n",
    "# Before the year of 2014 there is lack of general classification positions (GC) and time (GC Time) information\n",
    "tour_year_start = 2014\n",
    "tour_year_stop = 2018\n",
    "tour_years = list(range(tour_year_start, tour_year_stop+1))\n",
    "tour_years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tour results by stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tour years for analysis\n",
    "url_tour_results = []\n",
    "for year in tour_years:\n",
    "    url_tour_results.append(url_base + str(year))\n",
    "# url_tour_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of all stages in the above chosen tours\n",
    "url_stages_results = []\n",
    "for stage in url_tour_results:\n",
    "    for s in range(1,8):\n",
    "        url_stages_results.append(stage + '&k=etapper&e=0' + str(s))\n",
    "# url_stages_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Generating dictionaries of biker and team name with corresponding system number  that are needed for further steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of bikers participating in 2014\n",
      "Dictionary of bikers participating in 2015\n",
      "Dictionary of bikers participating in 2016\n",
      "Dictionary of bikers participating in 2017\n",
      "Dictionary of bikers participating in 2018\n"
     ]
    }
   ],
   "source": [
    "biker_dict_stage = {}\n",
    "team_dict_stage = {}\n",
    "i = tour_year_start - 1\n",
    "for stage in [stage for stage in url_stages_results if 'e=01' in stage]:\n",
    "    # Preparing dataframe with all racer names\n",
    "    dict_prep_ = pd.read_html(stage)\n",
    "    dict_prep = dict_prep_[0]\n",
    "    dict_prep['Name'] = dict_prep['Name'].str[0] + '.' + dict_prep['Name'].str.split(' ', 1, expand=True)[1]\n",
    "    \n",
    "    # Scraping system numbers\n",
    "    r = requests.get(stage)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    system_numbers = soup.find('table')\n",
    "\n",
    "    # Schema as `rider.php?r=2165` (2-5 digits with margin)\n",
    "    biker_system_nr = pd.DataFrame(re.findall('rider.php\\?r=(\\d{2,6})', str(system_numbers)), columns=['biker_sys_nr'])\n",
    "    # Schema as `team.php?l=8433` (3-4 digits with margin)\n",
    "    team_system_nr = pd.DataFrame(re.findall('team.php\\?l=(\\d{3,5})', str(system_numbers)), columns=['team_sys_nr'])\n",
    "    \n",
    "    # Merging team and rider names with their system numbers \n",
    "    biker_dict_stage_ = dict(zip(dict_prep['Name'], biker_system_nr['biker_sys_nr']))\n",
    "    biker_dict_stage.update(biker_dict_stage_)\n",
    "    team_dict_stage_ = dict(zip(dict_prep['Team'], team_system_nr['team_sys_nr']))\n",
    "    team_dict_stage.update(team_dict_stage_)\n",
    "    i += 1\n",
    "    print('Created dictionary of bikers participating in ' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(513, 69)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall number of bikers and teams\n",
    "len(biker_dict_stage), len(team_dict_stage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining datetime functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding leading zeros for further splitting based on ':' character\n",
    "def zeros_to_sec(df, col1, col2=False):\n",
    "    df[col1] = np.where(df[col1].str.len() == 2, '00:00:' + df[col1],'00:' + df[col1]) \n",
    "    df[col1] = df[col1].where(df[col1].str.len() != 11, df[col1].str.slice(3,11))\n",
    "    \n",
    "    if col2:\n",
    "        df[col2] = np.where(df[col2].str.len() == 2, '00:00:' + df[col2],'00:' + df[col2])\n",
    "        df[col2] = df[col2].where(df[col2].str.len() != 11, df[col2].str.slice(3,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Changind overall time into seconds\n",
    "def time_to_sec(df, col1, col2=False):\n",
    "    df[col1] = [(int(t[0])*3600 + int(t[1])*60 + int(t[2])) for t in df[col1].str.split(':')]\n",
    "    df[col1] = df[col1] + df[col1].max()\n",
    "    df.at[0, [col1]] = df[col1].max() / 2\n",
    "\n",
    "    if col2:\n",
    "        df[col2] = [(int(t[0])*3600 + int(t[1])*60 + int(t[2])) for t in df[col2].str.split(':')]\n",
    "        df[col2] = df[col2] + df[col2].max()\n",
    "        df.at[df[col2].idxmax(), [col2]] = df[col2].max() / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping tour's stage-by-stage info for adding new columns with extended statistics. The output is `stages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using URLs with all-year stages results\n",
    "# url_stages_results[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped tour of 2014 / 1\n",
      "Scraped tour of 2014 / 2\n",
      "Scraped tour of 2014 / 3\n",
      "Scraped tour of 2014 / 4\n",
      "Scraped tour of 2014 / 5\n",
      "Scraped tour of 2014 / 6\n",
      "Scraped tour of 2014 / 7\n",
      "Scraped tour of 2015 / 1\n",
      "Scraped tour of 2015 / 2\n",
      "Scraped tour of 2015 / 3\n",
      "Scraped tour of 2015 / 4\n",
      "Scraped tour of 2015 / 5\n",
      "Scraped tour of 2015 / 6\n",
      "Scraped tour of 2015 / 7\n",
      "Scraped tour of 2016 / 1\n",
      "Scraped tour of 2016 / 2\n",
      "Scraped tour of 2016 / 3\n",
      "Scraped tour of 2016 / 4\n",
      "Scraped tour of 2016 / 5\n",
      "There is no data for this stage. Skipping...\n",
      "Scraped tour of 2016 / 7\n",
      "Scraped tour of 2017 / 1\n",
      "Scraped tour of 2017 / 2\n",
      "Scraped tour of 2017 / 3\n",
      "Scraped tour of 2017 / 4\n",
      "Scraped tour of 2017 / 5\n",
      "Scraped tour of 2017 / 6\n",
      "Scraped tour of 2017 / 7\n",
      "Scraped tour of 2018 / 1\n",
      "Scraped tour of 2018 / 2\n",
      "Scraped tour of 2018 / 3\n",
      "Scraped tour of 2018 / 4\n",
      "Scraped tour of 2018 / 5\n",
      "Scraped tour of 2018 / 6\n",
      "Scraped tour of 2018 / 7\n"
     ]
    }
   ],
   "source": [
    "stages_ = []\n",
    "\n",
    "for year in tour_years:\n",
    "    i = 1\n",
    "    for stage_ in [stage_ for stage_ in url_stages_results if 'y='+str(year) in stage_]:\n",
    "        try:\n",
    "            stages__ = pd.read_html(stage_)\n",
    "            stages__ = stages__[0]\n",
    "            stages__['year'] = year\n",
    "            # Limiting number of stages in each year to 7\n",
    "            if i <= 7:\n",
    "                stages__['stage'] = i\n",
    "            else:\n",
    "                i = 1        \n",
    "            stages__.columns = ['position','to_drop','name','age','team','time_in_s','gc','gc_time_in_s','year','stage']\n",
    "            stages__['age'] = year - stages__['age']\n",
    "            stages__.replace(to_replace=r'\\+ ', value='', regex=True, inplace=True)\n",
    "            stages__.replace(to_replace=[np.NaN], value='00', inplace=True)\n",
    "            zeros_to_sec(stages__, 'time_in_s','gc_time_in_s')\n",
    "            time_to_sec(stages__, 'time_in_s','gc_time_in_s')\n",
    "            stages_.append(stages__)\n",
    "            print('Scraped tour of', year, '/', i)\n",
    "            i += 1\n",
    "        except ValueError:\n",
    "            print('There is no data for this stage. Skipping...')\n",
    "            i += 1\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mergind above stages\n",
    "stages = pd.concat(stages_, axis=0)\n",
    "stages.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Dropping useless columns\n",
    "stages.drop('to_drop', axis=1, inplace=True)\n",
    "\n",
    "# Replacing 'Did Not Finished' and 'Did Not Start' with some high value\n",
    "stages.replace(to_replace=['DNF', 'DNS'], value=999, inplace=True)\n",
    "stages['position'] = stages['position'].astype('int')\n",
    "\n",
    "# Shortening bikers names into 'initial.surname' form\n",
    "stages['name'] = stages['name'].str[0] + '.' + stages['name'].str.split(' ', 1, expand=True)[1]\n",
    "\n",
    "# Biker and Team system numbers\n",
    "stages['biker_sys_nr'] = stages['name'].map(biker_dict_stage)\n",
    "stages['team_sys_nr'] = stages['team'].map(team_dict_stage)\n",
    "\n",
    "# Rearranging columns\n",
    "stages = stages[['name','biker_sys_nr','age','team','team_sys_nr','time_in_s','gc','gc_time_in_s','year','stage','position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>biker_sys_nr</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>team_sys_nr</th>\n",
       "      <th>time_in_s</th>\n",
       "      <th>gc</th>\n",
       "      <th>gc_time_in_s</th>\n",
       "      <th>year</th>\n",
       "      <th>stage</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y.Hutarovich</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>AG2R La Mondiale</td>\n",
       "      <td>10072</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20860.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R.Maikin</td>\n",
       "      <td>14004</td>\n",
       "      <td>24</td>\n",
       "      <td>RusVelo</td>\n",
       "      <td>3482</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>2</td>\n",
       "      <td>20864.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M.Mori</td>\n",
       "      <td>492</td>\n",
       "      <td>34</td>\n",
       "      <td>Lampre - Merida</td>\n",
       "      <td>6418</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20866.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G.Boivin</td>\n",
       "      <td>1937</td>\n",
       "      <td>25</td>\n",
       "      <td>Cannondale Pro Cycling</td>\n",
       "      <td>3481</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M.Haller</td>\n",
       "      <td>6246</td>\n",
       "      <td>23</td>\n",
       "      <td>Team Katusha</td>\n",
       "      <td>8441</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>7</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           name biker_sys_nr  age                    team team_sys_nr  \\\n",
       "0  Y.Hutarovich          100   31        AG2R La Mondiale       10072   \n",
       "1      R.Maikin        14004   24                 RusVelo        3482   \n",
       "2        M.Mori          492   34         Lampre - Merida        6418   \n",
       "3      G.Boivin         1937   25  Cannondale Pro Cycling        3481   \n",
       "4      M.Haller         6246   23            Team Katusha        8441   \n",
       "\n",
       "   time_in_s  gc  gc_time_in_s  year  stage  position  \n",
       "0    20870.0   1       20860.0  2014      1         1  \n",
       "1    20870.0   2       20864.0  2014      1         2  \n",
       "2    20870.0   3       20866.0  2014      1         3  \n",
       "3    20870.0   6       20870.0  2014      1         4  \n",
       "4    20870.0   7       20870.0  2014      1         5  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating columns with different statistics** for each biker. The output is `biker_by_stage` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'n_stages'           - number of stages started\n",
    "'last_tour'          - number of years from last tour\n",
    "'best_pos_ovr'       - best position from all stages\n",
    "'worst_pos_ovr'      - worst position from all stages\n",
    "'avg_pos_ovr'        - average position from all stages\n",
    "'n_top10_ovr'        - number of top10 positions in all stages \n",
    "'perc_win_ovr'       - percentage of winning throughout all stages\n",
    "'perc_top10_ovr'     - percentage of being in top10 in all stages\n",
    "'avg_speed_ovr'      - average speed throughout all stages\n",
    "'best_pos_l...'      - best position from last 1-3 stages\n",
    "'wors_pos_l...'      - etc...\n",
    "'avg_pos_l...'\n",
    "'n_top10_l...'\n",
    "'perc_win_l...'\n",
    "'perc_top10_l...'\n",
    "'avg_speed_l...'\n",
    "'''\n",
    "\n",
    "biker_by_stage_ = pd.DataFrame()\n",
    "\n",
    "# Number of tours and stages ridden\n",
    "biker_by_stage_['n_tours'] = stages.groupby(['name'])['year'].nunique()\n",
    "biker_by_stage_['n_stages'] = stages.groupby(['name'])['stage'].count()\n",
    "\n",
    "# Best, average and worst tour stats\n",
    "min_max_ovr = stages.groupby('name')[['position','time_in_s','gc','gc_time_in_s']].agg(['min','mean','max'])\n",
    "\n",
    "# Number of Top10 positions\n",
    "top10 = pd.DataFrame(stages.groupby(stages[stages['position'] <= 10]['name'])['position'].count())\n",
    "\n",
    "# Number of winning stage\n",
    "winner_ = pd.DataFrame(stages.groupby(stages[stages['position'] == 1]['name'])['position'].count())\n",
    "\n",
    "# Defining last 3 stages data for stats purpose\n",
    "last_3_stages = stages.sort_values(['name','year','stage']).groupby('name').tail(3)\n",
    "min_max_avg_l3 = last_3_stages.groupby('name')[['position','time_in_s','gc','gc_time_in_s']].agg(['min','mean','max'])\n",
    "top10_l3 = pd.DataFrame(last_3_stages[last_3_stages['position'] <= 10]['name'].value_counts())\n",
    "winner_l3 = pd.DataFrame(last_3_stages.groupby(last_3_stages[last_3_stages['position'] == 1]['name'])['position'].count())\n",
    "\n",
    "biker_by_stage_ = pd.concat([biker_by_stage_, min_max_ovr, top10, winner_, min_max_avg_l3, top10_l3, winner_l3], axis=1, sort=False)\n",
    "biker_by_stage_ = biker_by_stage_.replace(np.NaN, 0)\n",
    "biker_by_stage_.columns = ['n_tours','n_stages','best_pos_ovr','avg_pos_ovr','worst_pos_ovr','best_time_ovr','avg_time_ovr','worst_time_ovr',\n",
    "                         'best_gc_ovr','avg_gc_ovr','worst_gc_ovr','best_gc_time_ovr','avg_gc_time_ovr','worst_gc_time_ovr','n_top10_ovr','n_win_ovr',\n",
    "                         'best_pos_ovr_l3','avg_pos_ovr_l3','worst_pos_ovr_l3','best_time_ovr_l3','avg_time_ovr_l3','worst_time_ovr_l3',\n",
    "                         'best_gc_ovr_l3','avg_gc_ovr_l3','worst_gc_ovr_l3','best_gc_time_ovr_l3','avg_gc_time_ovr_l3','worst_gc_time_ovr_l3',\n",
    "                         'n_top10_l3','n_win_l3']\n",
    "\n",
    "# Percentage of Top10 and winnig stage\n",
    "biker_by_stage_['perc_top10_ovr'] = biker_by_stage_['n_top10_ovr'] / biker_by_stage_['n_stages']\n",
    "biker_by_stage_['perc_win_ovr'] = biker_by_stage_['n_win_ovr'] / biker_by_stage_['n_stages']\n",
    "# biker_by_stage_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>biker_sys_nr</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>team_sys_nr</th>\n",
       "      <th>time_in_s</th>\n",
       "      <th>gc</th>\n",
       "      <th>gc_time_in_s</th>\n",
       "      <th>year</th>\n",
       "      <th>stage</th>\n",
       "      <th>...</th>\n",
       "      <th>best_gc_ovr_l3</th>\n",
       "      <th>avg_gc_ovr_l3</th>\n",
       "      <th>worst_gc_ovr_l3</th>\n",
       "      <th>best_gc_time_ovr_l3</th>\n",
       "      <th>avg_gc_time_ovr_l3</th>\n",
       "      <th>worst_gc_time_ovr_l3</th>\n",
       "      <th>n_top10_l3</th>\n",
       "      <th>n_win_l3</th>\n",
       "      <th>perc_top10_ovr</th>\n",
       "      <th>perc_win_ovr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y.Hutarovich</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>AG2R La Mondiale</td>\n",
       "      <td>10072</td>\n",
       "      <td>20870.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20860.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117</td>\n",
       "      <td>91441.0</td>\n",
       "      <td>104600.666667</td>\n",
       "      <td>112168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y.Hutarovich</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>AG2R La Mondiale</td>\n",
       "      <td>10072</td>\n",
       "      <td>19455.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40315.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117</td>\n",
       "      <td>91441.0</td>\n",
       "      <td>104600.666667</td>\n",
       "      <td>112168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y.Hutarovich</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>AG2R La Mondiale</td>\n",
       "      <td>10072</td>\n",
       "      <td>13167.0</td>\n",
       "      <td>2</td>\n",
       "      <td>53482.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117</td>\n",
       "      <td>91441.0</td>\n",
       "      <td>104600.666667</td>\n",
       "      <td>112168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y.Hutarovich</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>AG2R La Mondiale</td>\n",
       "      <td>10072</td>\n",
       "      <td>20609.0</td>\n",
       "      <td>3</td>\n",
       "      <td>74091.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117</td>\n",
       "      <td>91441.0</td>\n",
       "      <td>104600.666667</td>\n",
       "      <td>112168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y.Hutarovich</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>AG2R La Mondiale</td>\n",
       "      <td>10072</td>\n",
       "      <td>17350.0</td>\n",
       "      <td>98</td>\n",
       "      <td>91441.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117</td>\n",
       "      <td>91441.0</td>\n",
       "      <td>104600.666667</td>\n",
       "      <td>112168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name biker_sys_nr  age              team team_sys_nr  time_in_s  \\\n",
       "0  Y.Hutarovich          100   31  AG2R La Mondiale       10072    20870.0   \n",
       "1  Y.Hutarovich          100   31  AG2R La Mondiale       10072    19455.0   \n",
       "2  Y.Hutarovich          100   31  AG2R La Mondiale       10072    13167.0   \n",
       "3  Y.Hutarovich          100   31  AG2R La Mondiale       10072    20609.0   \n",
       "4  Y.Hutarovich          100   31  AG2R La Mondiale       10072    17350.0   \n",
       "\n",
       "   gc  gc_time_in_s  year  stage      ...       best_gc_ovr_l3  avg_gc_ovr_l3  \\\n",
       "0   1       20860.0  2014      1      ...                   98          109.0   \n",
       "1   2       40315.0  2014      2      ...                   98          109.0   \n",
       "2   2       53482.0  2014      3      ...                   98          109.0   \n",
       "3   3       74091.0  2014      4      ...                   98          109.0   \n",
       "4  98       91441.0  2014      5      ...                   98          109.0   \n",
       "\n",
       "   worst_gc_ovr_l3  best_gc_time_ovr_l3  avg_gc_time_ovr_l3  \\\n",
       "0              117              91441.0       104600.666667   \n",
       "1              117              91441.0       104600.666667   \n",
       "2              117              91441.0       104600.666667   \n",
       "3              117              91441.0       104600.666667   \n",
       "4              117              91441.0       104600.666667   \n",
       "\n",
       "   worst_gc_time_ovr_l3  n_top10_l3  n_win_l3  perc_top10_ovr  perc_win_ovr  \n",
       "0              112168.0         0.0       0.0        0.571429      0.142857  \n",
       "1              112168.0         0.0       0.0        0.571429      0.142857  \n",
       "2              112168.0         0.0       0.0        0.571429      0.142857  \n",
       "3              112168.0         0.0       0.0        0.571429      0.142857  \n",
       "4              112168.0         0.0       0.0        0.571429      0.142857  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging above results\n",
    "biker_by_stage = pd.merge(stages, biker_by_stage_, left_on='name', right_on=biker_by_stage_.index)\n",
    "biker_by_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining label (dependent variable)\n",
    "# 1 is the result of being in the Top 10 position at the given stage.\n",
    "biker_by_stage['y_label'] = np.where(biker_by_stage['position'] <= 10, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting all DNFs/DNSs to 999 and corresponding `time_in_s` i `gc_time_in_s` values to twice the last finisher time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually setting captured jerseys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "# Stages summary\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url_tour_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stages_summary = []\n",
    "for tour in url_tour_results:\n",
    "    url_stages_summary.append(tour + '&k=etapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_stages_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stages_summary_ = []\n",
    "for year in tour_years:\n",
    "    for stage in [stage for stage in url_stages_summary if 'y='+str(year) in stage]:\n",
    "        stages_summary__ = pd.read_html(stage)\n",
    "        stages_summary__ = pd.DataFrame(stages_summary__[0])\n",
    "        stages_summary__['year'] = year\n",
    "        stages_summary_.append(stages_summary__)\n",
    "stages_summary = pd.concat(stages_summary_, axis=0)\n",
    "stages_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying stage type by its icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utworzenie słownika z nazw etapów po norwesku i odp. im angielskim znaczeniom\n",
    "# stage_names_nor = list(set(stage_type))\n",
    "stage_names_nor = ['Flatt','Smaakupert','Smaakupert-MF','Fjell','Fjell-MF', 'Tempo']\n",
    "stage_names_en = ['flat','hilly','hilly-mf','mountain','mountain-mf','itt']\n",
    "stage_names = dict(zip(stage_names_nor, stage_names_en))\n",
    "stage_type_recode = dict(zip(stage_names_nor, list(range(1,7)))) \n",
    "\n",
    "stage_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# historycznie pojawiło się jeszcze jako 8 etap:\n",
    "# Bakketempo : mountain-itt; Ukjent : znak zapytania; \n",
    "\n",
    "stage_type = []\n",
    "for stage in url_stages_summary:\n",
    "    r = requests.get(stage)\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "\n",
    "    # selekcja wszystkich ścieżek do plików z nazwami typu etapu\n",
    "    stage_soup = soup.find_all('img')\n",
    "    stage_img = re.findall('([A-Z][a-z].*?)\\.gif', str(stage_soup))\n",
    "    \n",
    "    # selekcja tylko nazw odp. nazwom typów etapów wg. schematu regex i usunięcie nazw innych niż etapowe\n",
    "    for name_ in stage_img:\n",
    "        if name_ in stage_names_nor:\n",
    "            stage_type.append(name_)\n",
    "            \n",
    "stage_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns rearranging and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stages_summary['Unnamed: 1'] = stage_type\n",
    "\n",
    "stages_summary.columns = ['stage','stage_type','date','dist','to_drop','finish','stage_winner','stage_leader','points_leader','mountains_leader','sprint_leader','year']\n",
    "stages_summary['stage_type_code'] = stages_summary['stage_type'].map(stage_type_recode)\n",
    "stages_summary = stages_summary[['date','year','stage','stage_type','stage_type_code','dist','to_drop','finish','stage_winner','stage_leader','points_leader','mountains_leader','sprint_leader']]\n",
    "\n",
    "stages_summary['stage_type'] = stages_summary['stage_type'].map(stage_names)\n",
    "\n",
    "stages_summary.drop('to_drop', axis=1, inplace=True)\n",
    "stages_summary = stages_summary.loc[:, 'date':'finish'].reset_index(drop=True)\n",
    "stages_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stages_summary.groupby('year').agg(('min','max'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting stage date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages_summary['date'] = stages_summary['date'] + '.' + stages_summary['year'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stages_summary['date'] = pd.to_datetime(stages_summary['date'], format='%d.%b.%Y')\n",
    "stages_summary['date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biorę pod uwagę Opady(0/1), Temperatura (float), ew. czy było zachmurzenie\n",
    "# https://dane.imgw.pl/data/dane_pomiarowo_obserwacyjne/\n",
    "\n",
    "'''\n",
    "Kod stacji                        9\n",
    "Nazwa stacji                     30\n",
    "Rok                               4\n",
    "Miesiąc                           2\n",
    "Dzień                             2\n",
    "Godzina                           2\n",
    "Temperatura powietrza             6/1\n",
    "Status pomiaru TEMP               1\n",
    "Temperatura termometru zwilżonego 6/1\n",
    "Status pomiaru TTZW               1\n",
    "Wskaźnik lodu                     1\n",
    "Wskaźnik wentylacji               1\n",
    "Wilgotność względna               5\n",
    "Status pomiaru WLGW               1\n",
    "Kod kierunku wiatru               3\n",
    "Status pomiaru DKDK               1\n",
    "Prędkość wiatru                   5\n",
    "Status pomiaru FWR                1\n",
    "Zachmurzenie ogólne               5\n",
    "Status pomiaru ZOGK               1\n",
    "Widzialność                       5\n",
    "Status pomiaru WID                1\n",
    "\n",
    "Status \"8\" brak pomiaru\n",
    "Zachmurzenie\n",
    "        - skala 0 - 10 do dn.31.12.1988\n",
    "        - skala 0 – 8 od dn.01.01.1989\n",
    "'''\n",
    "\n",
    "# PO UDOSTĘPNIENIU DANYCH POGODOWYCH ZMIENIĆ NA OBECNY ROK\n",
    "\n",
    "names = ['station_code','station_name','year','month','day','hour',\n",
    "         'temp','temp_status','wet_temp','ttzw_status','ice_ind','vent_ind',\n",
    "         'rel_humid','wlgw_status','wind_dir','dkdk_status','wind_speed','fwr_status',\n",
    "         'clouds_ovrl','zogk_status','visibility','wid_status']\n",
    "\n",
    "weather_08_14 = pd.read_csv('data/weather_k_t_08_2014.csv', encoding = 'ISO-8859-2', header=None, names=names)\n",
    "weather_08_15 = pd.read_csv('data/weather_k_t_08_2015.csv', encoding = 'ISO-8859-2', header=None, names=names)\n",
    "weather_07_16 = pd.read_csv('data/weather_k_t_07_2016.csv', encoding = 'ISO-8859-2', header=None, names=names)\n",
    "weather_07_17 = pd.read_csv('data/weather_k_t_07_2017.csv', encoding = 'ISO-8859-2', header=None, names=names)\n",
    "weather_08_17 = pd.read_csv('data/weather_k_t_08_2017.csv', encoding = 'ISO-8859-2', header=None, names=names)\n",
    "\n",
    "# TU TRZEBA POBRAĆ NOWE DANE Z ODPOWIEDNICH MIESIĘCY\n",
    "weather_07_18 = pd.read_csv('data/weather_k_t_05_2018.csv', encoding = 'ISO-8859-2', header=None, names=names)\n",
    "weather_08_18 = pd.read_csv('data/weather_k_t_06_2018.csv', encoding = 'ISO-8859-2', header=None, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_07_18['month'] = 7\n",
    "weather_08_18['month'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_info = pd.concat([weather_08_14, weather_08_15,weather_07_16,\n",
    "                          weather_07_17, weather_08_17, weather_08_18], axis=0)\n",
    "weather_info = weather_info[weather_info.hour == 12].reset_index(drop=True)\n",
    "weather_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_info['date'] = weather_info['year'].astype('str') + '.' +\\\n",
    "                       weather_info['month'].astype('str') + '.' +\\\n",
    "                       weather_info['day'].astype('str')\n",
    "weather_info['date'] = pd.to_datetime(weather_info['date'], format='%Y.%m.%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weather_info[weather_info.date.isin(stages_summary.date) & (weather_info.year == 2018) & weather_info.station_name.str.contains('KRAK')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tour_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_stages = pd.DataFrame()\n",
    "for year in tour_years:\n",
    "    # Stage 1\n",
    "    st1_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('KRAK')].iloc[0] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    # Stage 2\n",
    "    st2_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('DRONI')].iloc[1] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    # Stage 3\n",
    "    st3_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('BRENNA')].iloc[2] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    # Stage 4\n",
    "    st4_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('DRONI')].iloc[3] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    # Stage 5\n",
    "    st5_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('CHORZ')].iloc[4] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    # Stage 6\n",
    "    st6_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('LIMA')].iloc[5] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    # Stage 7\n",
    "    st7_weather = weather_info[weather_info.date.isin(stages_summary.date) \\\n",
    "                    & (weather_info.year == year) \\\n",
    "                    & weather_info.station_name.str.contains('BUKOW')].iloc[6] \\\n",
    "                    [['temp','rel_humid','wind_dir','wind_speed','clouds_ovrl','visibility']]\n",
    "    weather_stages = weather_stages.append([st1_weather, st2_weather, st3_weather, st4_weather,\n",
    "                           st5_weather, st6_weather, st7_weather]).reset_index(drop=True)\n",
    "#     weather_stages.append(stages_weather_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weather_stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining stage summary, weather info and biker stage position list dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stages_summary = pd.concat([stages_summary, weather_stages], axis=1)\n",
    "stages_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stages_summary_cut = stages_summary.loc[:,'date':'visibility']\n",
    "# stages_summary_cut.to_csv('data/stages_summary_cut.csv', index=False)\n",
    "# stages_summary_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "# Bikers statistics and overall description\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall bikers list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista wszystkich kolarzy\n",
    "biker_base_url = 'http://firstcycling.com/rider.php?r='\n",
    "\n",
    "bikers_ranking_urls = []\n",
    "for k,v in biker_dict_stage.items():\n",
    "    bikers_ranking_urls.append(biker_base_url + v)\n",
    "len(bikers_ranking_urls)\n",
    "# pd.DataFrame(bikers_ranking_urls)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scapring bikers stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bikers_stats_ = pd.DataFrame()\n",
    "i = -1\n",
    "# bikers_ranks_ = []\n",
    "for url_ in bikers_ranking_urls:\n",
    "\n",
    "    # Stats scraping with the season-by-season separation\n",
    "    r = requests.get(url_)\n",
    "    table_ = pd.read_html(r.text)   \n",
    "    # Settig 'Season' column as an index for dataframe transposition\n",
    "    biker_rank = table_[0].loc[:4,:].set_index('Season')\n",
    "    biker_rank.columns = ['div','team','fc_rank','to_drop','uci_rank','to_drop','race_days','wins','year_km']\n",
    "    biker_rank.drop(['to_drop'], axis=1, inplace=True)\n",
    "    # Dataframe transposition\n",
    "    biker_rank = biker_rank.stack().to_frame().T\n",
    "    # Renaming column names\n",
    "    biker_rank.columns = ['{}_{}'.format(*c) for c in biker_rank.columns]  \n",
    "    # Removing duplicate rows\n",
    "    biker_rank = biker_rank.loc[:,~biker_rank.columns.duplicated()]\n",
    "    \n",
    "    # Physical stats, nationality, jerseys, wictories and followers extraction\n",
    "    soup = BeautifulSoup(r.text,'html.parser')\n",
    "    stats = soup.find_all('div', class_='back')\n",
    "    \n",
    "    nation = re.findall('nat=.*?>(\\w.*?)<|$', str(stats))[0]\n",
    "    try:\n",
    "        height = re.findall('Height.*?(\\d{1}\\.\\d{2})|$', str(stats))[0] \n",
    "    except (ValueError, IndexError):\n",
    "        height = np.NaN\n",
    "    try:\n",
    "        wins_search = re.search('Victories.*?<h2', str(stats)).group() \n",
    "        total_wins = len(re.findall('\\d{4}(,|\\))', wins_search))\n",
    "    except (AttributeError, ValueError, IndexError):\n",
    "        total_wins = 0\n",
    "    try:\n",
    "        youth_search = re.search('Youth.*?<\\/p', str(stats)).group()\n",
    "        youth_jersey = len(re.findall('[( ,](\\d{4})', youth_search))\n",
    "    except (AttributeError, ValueError, IndexError):\n",
    "        youth_jersey = 0\n",
    "    try:\n",
    "        point_search = re.search('Points.*?<\\/p', str(stats)).group()\n",
    "        point_jersey = len(re.findall('[( ,](\\d{4})', point_search))\n",
    "    except (AttributeError, ValueError, IndexError):\n",
    "        point_jersey = 0\n",
    "    try:\n",
    "        mount_search = re.search('Mount.*?<\\/p', str(stats)).group()\n",
    "        mount_jersey = len(re.findall('[( ,](\\d{4})', mount_search))\n",
    "    except (AttributeError, ValueError, IndexError):\n",
    "        mount_jersey = 0\n",
    "    try:\n",
    "        sprint_search = re.search('Sprint.*?<\\/p', str(stats)).group()\n",
    "        sprint_jersey = len(re.findall('[( ,](\\d{4})', sprint_search))\n",
    "    except (AttributeError, ValueError, IndexError):\n",
    "        sprint_jersey = 0\n",
    "    try:\n",
    "        followers_soup = soup.find_all('p', class_='small')\n",
    "        followers = len(re.findall('ID', str(followers_soup)))\n",
    "    except (AttributeError, ValueError, IndexError):\n",
    "        followers = 0\n",
    "    \n",
    "    # zebranie powyższych danych w formę ramki\n",
    "    results_dict = {\n",
    "        'nation':nation,\n",
    "        'height':height,\n",
    "        'total_wins':total_wins,\n",
    "        'youth_jerseys':youth_jersey,\n",
    "        'point_jerseys':point_jersey,\n",
    "        'mount_jerseys':mount_jersey,\n",
    "        'sprint_jerseys':sprint_jersey,\n",
    "        'followers':followers\n",
    "    }\n",
    "    stats_table = pd.DataFrame(data=results_dict, index=[0])\n",
    "    \n",
    "    # konkatenacja obu wynikowych ramek\n",
    "    biker_rank = pd.concat([biker_rank, stats_table], axis=1)\n",
    "    i += 1\n",
    "    print('Scrapped position no.', i, nation, height, total_wins, youth_jersey, point_jersey, mount_jersey, sprint_jersey, followers)\n",
    "#     bikers_ranks_.append(biker_rank)\n",
    "    bikers_stats_ = bikers_stats_.append(biker_rank, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sortowanie kolumn alfabetycznie\n",
    "bikers_stats_.sort_index(axis=1, inplace=True)\n",
    "\n",
    "# przypisanie indexu z kolejnych kluczy ze słownika (dodam jednak jako kolumnę w innym kroku)\n",
    "# bikers_ranks.index = [k for k,v in biker_dict_stage.items()][:len(bikers_ranks)]\n",
    "bikers_stats_['name'] = [k for k,v in biker_dict_stage.items()][:len(bikers_stats_)]\n",
    "\n",
    "# resetuję index do późniejszej konkatenacji tabel\n",
    "bikers_stats_.reset_index(drop=True, inplace=True)\n",
    "bikers_stats_['height'].replace('', np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the whole historical results dataset (2013-2019) choosing only years 2015-2018 due to many missing values before that timepoint\n",
    "bikers_stats = pd.concat([bikers_stats_.loc[:,'2015_div':'2018_year_km'], bikers_stats_.iloc[:,-9:]], axis=1)\n",
    "bikers_stats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting final biker class dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biker_by_stage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikers_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating biker class dataset\n",
    "# Concatenating historical stats with last tour results by stages\n",
    "biker_class = pd.merge(biker_by_stage, bikers_stats, left_on='name', right_on='name')\n",
    "biker_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biker_class.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearranging columns for clearness\n",
    "cols = biker_class.columns.tolist()\n",
    "cols = cols[-9:] + cols[:-9]\n",
    "biker_class = biker_class[cols]\n",
    "biker_class = biker_class.reindex(columns=['name','nation','height','age','total_wins','youth_jerseys',\n",
    "                             'point_jerseys','mount_jerseys','sprint_jerseys','followers','year']+cols[11:])\n",
    "# biker_class.drop('name_to_drop', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biker_class.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking columns with missing data\n",
    "biker_class_null_cols = biker_class.columns[biker_class.isnull().any()]\n",
    "biker_class[biker_class_null_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>\n",
    "# Final dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next notebook:** [Part 2: Data statistics and visualization](tdp_2_3_data_statistics_visualization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall stages summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu dodać dla każdego etapu dane pogodowe: deszcz/słońce(temp)\n",
    "# stages_summary.to_csv('preprocessed/stages_summary.csv', index=False)\n",
    "# stages_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tour results by stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tu etapy są jeden pod drugim, więc numery 'position' się powtarzają 1-154 x 7 etapów \n",
    "# stages.to_csv('preprocessed/stages.csv', index=False)\n",
    "# stages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biker by stage results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biker_by_stage.to_csv('preprocessed/biker_by_stage.csv')\n",
    "# biker_by_stage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historical bikers data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bikers_stats.to_csv('preprocessed/biker_stats.csv')\n",
    "# bikers_stats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final biker class dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "biker_class.to_csv('preprocessed/biker_class.csv')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
